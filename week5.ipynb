{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Avenues - Week 5 \n",
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind Word2Vec is to learn word embeddings by training a shallow neural network on a large corpus of text. The training process is typically done using either the Skip-gram model or the Continuous Bag of Words (CBOW) model.\n",
    "\n",
    "Skip-gram model: This model predicts the context words (surrounding words) given a target word. It tries to maximize the probability of predicting the context words accurately based on the target word.\n",
    "\n",
    "Continuous Bag of Words (CBOW) model: This model, on the other hand, predicts the target word given its context words. It aims to maximize the probability of predicting the target word based on its surrounding context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the dataset and create a list for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"open_ave_data.csv\")\n",
    "df.fillna(\"nan\",inplace=True)\n",
    "\n",
    "findings = df[\"findings\"].values.tolist()\n",
    "clinical = df[\"clinicaldata\"].values.tolist()\n",
    "exam = df[\"ExamName\"].values.tolist()\n",
    "impression = df[\"impression\"].values.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to clean the dataset. Removing any unnecessary words or characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list=stopwords.words('english')\n",
    "\n",
    "def clean_data(w):\n",
    "    w = w.lower()\n",
    "    w=re.sub(r'[^\\w\\s]','',w)\n",
    "    w=re.sub(r\"([0-9])\", r\" \",w)\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function to process all the sentences from each corpus. It uses the clean_data function from above to clean the corpus by removing the stop words and any non alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(corpus):\n",
    "    sent=list(map(clean_data,corpus))               # Clean the sentences\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores= multiprocessing.cpu_count()\n",
    "model = Word2Vec(min_count=5,window=5,vector_size=300,workers=cores-1,max_vocab_size=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train the model, we must create the vocabulary for the corpus. Which represents all the unique tokens in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['findings', 'normal', 'pleural', 'pneumothorax', 'effusion', 'heart', 'mediastinum', 'within', 'focal', 'lungspleura', 'cardiomediastinal', 'opacities', 'lungs', 'none', 'evident', 'unremarkable', 'mediastinal', 'size', 'exam', 'contour', 'contours', 'limitations', 'clear', 'acute', 'limits', 'pulmonary', 'silhouette', 'osseous', 'abnormality', 'volumes', 'consolidation', 'structures', 'stable', 'significant', 'tube', 'effusions', 'lung', 'cardiac', 'infiltrate', 'right', 'chest', 'adenopathy', 'left', 'visualized', 'bony', 'vessels', 'atelectasis', 'seen', 'bone', 'tip', 'mild', 'bones', 'evidence', 'process', 'endotracheal', 'skeletal', 'appear', 'abnormalities', 'vascularity', 'vasculature', 'demonstrate', 'mass', 'vascular', 'edema', 'unchanged', 'identified', 'congestion', 'bilateral', 'either', 'fluid', 'catheter', 'noted', 'cardiomegaly', 'visible', 'changes', 'tubes', 'interstitial', 'portable', 'airspace', 'carina', 'enteric', 'upper', 'central', 'soft', 'intact', 'prior', 'infiltrates', 'hilar', 'lines', 'pleura', 'bibasilar', 'appears', 'view', 'similar', 'definite', 'perihilar', 'wellexpanded', 'diaphragm', 'change', 'enlarged', 'disease', 'views', 'hours', 'thoracic', 'confluent', 'lateral', 'well', 'compared', 'support', 'terminates', 'small', 'tissues', 'negative', 'fracture', 'svc', 'free', 'large', 'basilar', 'opacity', 'without', 'lower', 'enlargement', 'obtained', 'jugular', 'internal', 'thorax', 'lesion', 'approximately', 'parenchymal', 'picc', 'thickening', 'base', 'interval', 'new', 'lobe', 'region', 'expanded', 'remain', 'examination', 'venous', 'wires', 'line', 'lesions', 'shows', 'grossly', 'present', 'courses', 'aorta', 'aortic', 'single', 'persistent', 'hila', 'devices', 'position', 'frontal', 'air', 'increasing', 'consolidations', 'sternotomy', 'appearance', 'place', 'markings', 'distal', 'spine', 'increased', 'configuration', 'image', 'regional', 'stomach', 'extremity', 'minimal', 'degenerative', 'inflated', 'trachea', 'peribronchial', 'low', 'alveolar', 'tissue', 'wellaerated', 'aeration', 'good', 'body', 'failure', 'cuffing', 'demonstrates', 'costophrenic', 'anatomy', 'leads', 'midline', 'slightly', 'width', 'leftsided', 'swanganz', 'fields', 'spaces', 'mildly', 'opacification', 'expansion', 'diffuse', 'removed', 'normally', 'median', 'status', 'superior', 'linestubes', 'displaced', 'patchy', 'sharp', 'ribs', 'vena', 'aerated', 'atrium', 'andor', 'pneumonia', 'adequately', 'lobar', 'study', 'scarring', 'remaining', 'cava', 'cardiopulmonary', 'technique', 'mid', 'prominence', 'rightsided', 'otherwise', 'interim', 'sulci', 'degree', 'sternal', 'pacemaker', 'hazy', 'bases', 'submitted', 'appearing', 'proximal', 'silhouettes', 'nodules', 'calcification', 'parenchyma', 'space', 'radiopaque', 'additional', 'pathology', 'patients', 'persist', 'exhibits', 'active', 'yesterdays']\n"
     ]
    }
   ],
   "source": [
    "corpus = get_sentences(findings)\n",
    "\n",
    "# Building the vocabulary using entire dataset\n",
    "model.build_vocab(corpus)\n",
    "\n",
    "# This will be a dictionary with words as a key and keyedvectors object as the value.\n",
    "word_dict = model.wv.key_to_index\n",
    "\n",
    "# To see the words in the vocabulary\n",
    "keys = model.wv.index_to_key\n",
    "print(keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample =random.sample(corpus,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(841471, 1798300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(corpus,total_examples=model.corpus_count,epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a way to see similar words based on an input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clear', 0.6960206031799316),\n",
       " ('effusions', 0.6200727224349976),\n",
       " ('pulmonary', 0.5714744329452515),\n",
       " ('osseous', 0.5662592649459839),\n",
       " ('lungspleura', 0.5508614778518677)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"lungs\"],topn=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
